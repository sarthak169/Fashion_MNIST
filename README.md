# Fashion_MNIST

The Fashion MNIST dataset was created by e-commerce company, Zalando.It is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.
![Tnse](https://github.com/sarthak169/Fashion_MNIST/blob/master/t-SNE-on-Fashion-MNIST-test-set.png)
# Prerequisites
>- Python
>- Scikit-learn/Sklearn
>- Pandas
>- NumPy
>- Matplotlib
>- Seaborn
For Linux people, your package manager should be able to handle all of this. If it somehow can't, see if you can at least install Python and pip and then use pip to install the above packages

## DataSet Description
>- Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.
>- Each pixel has a single pixel value associated with it, indicating the lightness or darkness of that pixel(higher numbers meaning darker).
>- The pixel value is an integer between 0 and 255.
>- The training and testing datasets have 785 columns.
>- The first column in the dataset consist of class labels which represents the article of clothing.
>- The rest of the columns contain the pixel values of the associated image.
>- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are >-integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.
>- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top.
![](https://github.com/sarthak169/Fashion_MNIST/blob/master/label.PNG)

# Objectives
>- View the data as an image
>- Train different classifiers
>- Compare performance for different classifiers using various metrics
![](https://github.com/sarthak169/Fashion_MNIST/blob/master/fashion.png)

# Libraries Used 
>- Pandas
>- NumPy
>- Seaborn
>- Matplotlib.pyplot
>- Missingno
>- sklearn

# Training Models Used
>- Logistic Regression
>- KNN (K Nearest Neibhour)
>- Naive Bayes
>- Support Vector Machine(Linear)
>- SVM (Radial baised Function)
>- Decision Tree(Ginni)
>- Decision Tree(Entropy)
>- Random Forest Classifier(Ginni)
>- Random Forest Classifier(Entropy)

# Performance Mertices Used:
>- Accuracy Score
>- Confusion Matrix
>- Classification Report
